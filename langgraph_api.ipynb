{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGaNtMCIfYIHVv/G+5IR4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChintPatel/CMPE258-HW7/blob/main/langgraph_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "slZZsbKgaq7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71218fe7-223a-426d-c83c-6f209de4bd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain_core langchain-anthropic langgraph langsmith\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers accelerate torch langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqsfofmXGQIy",
        "outputId": "65fa1939-8686-48d1-a436-f2d205ebbc4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet google-genai langgraph\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import os\n",
        "from getpass import getpass\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "if not os.environ.get(\"GEMINI_API_KEY\"):\n",
        "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"GEMINI_API_KEY: \")\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBJDFAz2qSB",
        "outputId": "80507fff-ca91-4aa9-fed3-45d7cc604070"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GEMINI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶️ Cell 2: Configure LLM + Tracer"
      ],
      "metadata": {
        "id": "xRB1D7b_Gzf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab ▶️ Cell 2: Define a Gemini wrapper using the Google Gen AI SDK\n",
        "\n",
        "def call_gemini(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends `prompt` to Gemini via the Google Gen AI SDK\n",
        "    (free-tier API key) and returns the generated text.\n",
        "    \"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",    # or gemini-1.5-flash, gemini-2.0-vision, etc.\n",
        "        contents=prompt,             # can also pass a list for multimodal: [prompt, image_bytes]\n",
        "        # Optionally control length/temperature:\n",
        "        # config=types.GenerateContentConfig(\n",
        "        #     max_output_tokens=128,\n",
        "        #     temperature=0.7\n",
        "        # )\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# Quick sanity check:\n",
        "print(call_gemini(\"Write a short joke about cats\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG3DVFr1FrT3",
        "outputId": "a19e7a2a-97e5-43db-8991-0cffd8f2f1c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't cats play poker in the jungle? \n",
            "\n",
            "Too many cheetahs! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶️ Cell 3: Prompt‐Chaining Workflow"
      ],
      "metadata": {
        "id": "QPhOKb8wGwnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab ▶️ Cell 3: Prompt-Chaining Agent\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "class JokeState(TypedDict):\n",
        "    topic: str\n",
        "    joke: str\n",
        "    improved_joke: str\n",
        "\n",
        "def gen_joke(state: JokeState):\n",
        "    return {\"joke\": call_gemini(f\"Write a short joke about {state['topic']}\")}\n",
        "\n",
        "def has_punchline(state: JokeState) -> str:\n",
        "    return \"Pass\" if any(p in state[\"joke\"] for p in (\"?\", \"!\")) else \"Fail\"\n",
        "\n",
        "def improve_joke(state: JokeState):\n",
        "    return {\"improved_joke\": call_gemini(f\"Make this joke funnier: {state['joke']}\")}\n",
        "\n",
        "graph1 = StateGraph(JokeState)\n",
        "graph1.add_node(\"gen_joke\", gen_joke)\n",
        "graph1.add_conditional_edges(\"gen_joke\", has_punchline, {\n",
        "    \"Pass\": END,\n",
        "    \"Fail\": \"improve_joke\"\n",
        "})\n",
        "graph1.add_node(\"improve_joke\", improve_joke)\n",
        "graph1.add_edge(START, \"gen_joke\")\n",
        "graph1.add_edge(\"improve_joke\", END)\n",
        "\n",
        "chain1 = graph1.compile()\n"
      ],
      "metadata": {
        "id": "okyEVdJkGozb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶️ Cell 4: Invoke Prompt‐Chaining & View Trace"
      ],
      "metadata": {
        "id": "8X8feNzoGvdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab ▶️ Cell 4: Run Prompt-Chaining\n",
        "\n",
        "result1 = chain1.invoke({\"topic\": \"cats\"})\n",
        "print(\"Final joke:\", result1.get(\"joke\") or result1.get(\"improved_joke\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZU4cyNw4Nd6",
        "outputId": "5eed731e-f82d-4dbc-c0ad-59b27e891d33"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final joke: Why did the cat join the Red Cross? \n",
            "\n",
            "Because he wanted to be a first-aid kit! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶️ Cell 5: Parallelization Workflow"
      ],
      "metadata": {
        "id": "fcNSAwe4Gt2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab ▶️ Cell 5: Parallelization Agent\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "class ParState(TypedDict):\n",
        "    topic: str\n",
        "    joke: str\n",
        "    story: str\n",
        "    poem: str\n",
        "    combined: str  # include for the final step\n",
        "\n",
        "def call_joke(state: ParState):\n",
        "    return {\"joke\": call_gemini(f\"Write a joke about {state['topic']}\")}\n",
        "\n",
        "def call_story(state: ParState):\n",
        "    return {\"story\": call_gemini(f\"Write a short story about {state['topic']}\")}\n",
        "\n",
        "def call_poem(state: ParState):\n",
        "    return {\"poem\": call_gemini(f\"Write a poem about {state['topic']}\")}\n",
        "\n",
        "def combine_all(state: ParState):\n",
        "    return {\n",
        "        \"combined\": (\n",
        "            f\"JOKE:\\n{state['joke']}\\n\\n\"\n",
        "            f\"STORY:\\n{state['story']}\\n\\n\"\n",
        "            f\"POEM:\\n{state['poem']}\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "graph2 = StateGraph(ParState)\n",
        "# add the three LLM calls with unique node names\n",
        "graph2.add_node(\"call_joke\", call_joke)\n",
        "graph2.add_node(\"call_story\", call_story)\n",
        "graph2.add_node(\"call_poem\", call_poem)\n",
        "graph2.add_node(\"combine_all\", combine_all)\n",
        "\n",
        "# fan-in structure\n",
        "for node in (\"call_joke\", \"call_story\", \"call_poem\"):\n",
        "    graph2.add_edge(START, node)\n",
        "    graph2.add_edge(node, \"combine_all\")\n",
        "graph2.add_edge(\"combine_all\", END)\n",
        "\n",
        "chain2 = graph2.compile()\n"
      ],
      "metadata": {
        "id": "lsaEnKj6Gq27"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab ▶️ Cell 6: Run Parallelization\n",
        "\n",
        "result2 = chain2.invoke({\"topic\": \"cats\"})\n",
        "print(result2[\"combined\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tssK5wZI4T1W",
        "outputId": "1a52adc6-fcce-48e5-eb32-633a405e2474"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JOKE:\n",
            "Why did the cat join the Red Cross?\n",
            "\n",
            "Because he wanted to learn first aid!\n",
            "...You know, for when he gets into cat fights.\n",
            "\n",
            "\n",
            "STORY:\n",
            "The alley was their kingdom, a labyrinth of overflowing bins, sun-baked brick, and the comforting smell of forgotten things. Whiskers, a grizzled tabby with one ear permanently bent, ruled with the quiet authority of experience. He'd seen seasons come and go, kittens born and lost, and knew every crevice where a scrap of food could be found or a moment of peace stolen.\n",
            "\n",
            "Tonight, though, a tremor of unrest ran through the feline court. A newcomer had arrived. Midnight, a sleek, black she-cat with emerald eyes that pierced the darkness, had been scavenging at the edge of their territory for days. Whiskers had tolerated her presence, understanding the primal need for survival, but tonight, she was bolder. She sat right at the mouth of the alley, her gaze fixed on the overflowing bin where Whiskers kept his most prized treasure – a discarded, half-eaten tuna sandwich.\n",
            "\n",
            "He watched her, his tail twitching, a low growl rumbling in his chest. He wasn't usually territorial, but this sandwich… this was special. He rose, his old bones protesting with a crack, and stalked towards her.\n",
            "\n",
            "Midnight didn’t flinch. She met his gaze, a silent challenge in her luminous eyes. For a moment, they stood frozen, two shadows locked in a silent battle of wills. Then, a wail pierced the night.\n",
            "\n",
            "It was a kitten, its tiny voice echoing from the shadows. Midnight’s ears pricked. She turned, her focus immediately shifting from the sandwich to the source of the sound.\n",
            "\n",
            "Whiskers, momentarily forgotten, followed her gaze. He saw it then: a tiny, shivering ball of fur huddled beneath a discarded cardboard box. It was a calico, no more than a few weeks old, its eyes wide with fear.\n",
            "\n",
            "Midnight hesitated, then cautiously approached the box. She sniffed the kitten, then gently nudged it with her head. The kitten, initially startled, began to purr, a soft, desperate sound that resonated in the silent alley.\n",
            "\n",
            "Whiskers watched, his anger dissolving. He remembered his own beginnings, the cold loneliness of being abandoned. He understood now. Midnight wasn't challenging him for dominance. She was looking for food, not for herself, but for the kitten.\n",
            "\n",
            "He turned towards the bin, nudged the tuna sandwich with his nose, and pushed it towards Midnight. She looked up, surprised, her eyes softening. She nudged the sandwich towards the kitten, who eagerly began to devour it.\n",
            "\n",
            "Whiskers sat beside her, his old body comforting the tiny kitten. He purred, a deep, rumbling sound of contentment. The alley, for now, was safe. It wasn't just his kingdom anymore. It was their kingdom. And in the soft glow of the streetlights, under the watchful gaze of the moon, a new, unlikely family was born. The king, the newcomer, and the tiny princess, bound together by hunger, hardship, and the silent language of cats.\n",
            "\n",
            "\n",
            "POEM:\n",
            "With eyes of jade or amber bright,\n",
            "A velvet shadow in the night,\n",
            "The cat descends, a silent grace,\n",
            "A purring puzzle, time and space.\n",
            "\n",
            "A liquid form that seems to flow,\n",
            "From sunbeam's warmth to shadows low,\n",
            "A twitching tail, a flicking ear,\n",
            "Alert to whispers, far and near.\n",
            "\n",
            "A hunter's heart within the breast,\n",
            "A playful spirit, never at rest,\n",
            "A sudden leap, a graceful bound,\n",
            "Then silence reigns, without a sound.\n",
            "\n",
            "A rumbling motor, soft and deep,\n",
            "As weary humans drift to sleep,\n",
            "A comforting weight upon the knee,\n",
            "A feline friend, eternally.\n",
            "\n",
            "Independent, proud, and free,\n",
            "A sovereign soul, for all to see,\n",
            "Yet craving touch, a gentle stroke,\n",
            "A bond unbroken, hearts evoke.\n",
            "\n",
            "So hail the cat, in all its might,\n",
            "A creature of beauty, dark and light,\n",
            "A mystery wrapped in fur so sleek,\n",
            "The enigmatic cat, forever unique.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}